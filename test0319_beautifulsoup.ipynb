{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError,HTTPError\n",
    "try:\n",
    "    html=urlopen(\"http://java.com\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "    print(\"HTTP 에러\")\n",
    "except URLError as e:\n",
    "    print(e)\n",
    "    print(\"URL에러\")\n",
    "else:\n",
    "    print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve,urlopen\n",
    "url=\"https://imgnews.pstatic.net/image/025/2020/03/19/0002985409_001_20200319091403821.jpg?type=w647\"\n",
    "saveimage=\"data/images/img01.jpg\"\n",
    "urlretrieve(url,saveimage)\n",
    "print(\"이미지 저장\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://imgnews.pstatic.net/image/025/2020/03/19/0002985409_001_20200319091403821.jpg?type=w647\"\n",
    "saveimage=\"data/images/img02.jpg\"\n",
    "image=urlopen(url).read()\n",
    "with open(saveimage,mode='wb')as f:\n",
    "    f.write(image)\n",
    "print(\"이미지 저장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "html=urlopen(\"http://stackoverflow.com\")\n",
    "bs=soup(html.read(),'html.parser')\n",
    "print(bs.title)\n",
    "print(bs.title.text)\n",
    "print(bs.h1)\n",
    "print(bs.h1.text)\n",
    "print(bs.span)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=urlopen(\"https://www.naver.com\").read()\n",
    "bs=soup(html,'html.parser')\n",
    "print(bs.a)\n",
    "print(bs.a.text)\n",
    "print(bs.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=urlopen(\"https://www.naver.com\").read()\n",
    "bs=soup(html,'html.parser')\n",
    "images=bs.find_all('img')\n",
    "i=0\n",
    "for image in images:\n",
    "    src=image.attrs['src']\n",
    "    ext=src[src.rindex('.'):]\n",
    "    print(ext)\n",
    "    save_name=\"data/images/img\"+str(i)+ext\n",
    "    i=i+1\n",
    "    urlretrieve(src,save_name)\n",
    "    #indexOf(\"문자열\"):index('문자열'), 문자열의 위치 왼쪽부터\n",
    "    #lastIndexOf(\"문자열\"):rindex('문자열'), 문자열위치 오른쪽부터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=urlopen(\"https://www.naver.com\").read()\n",
    "bs=soup(html,'html.parser')\n",
    "links=bs.find_all('a')\n",
    "for link in links:\n",
    "    href=link.attrs['href']\n",
    "    text=link.string\n",
    "    print(text,href)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BeautifulSoup 스크래핑 방법\n",
    "# bs=BeautifulSoup(html.read(),'html.parser')\n",
    "# 1) bs.태그.태그 : element 찾음\n",
    "# 2) bs.find(선택자):element 찾음, 선택자: tag, id, class: \n",
    "# 3) bs.find_all(선택자) : elements 를 찾음\n",
    "# 4) bs.select_one(path): 1개 element , div > ul > li\n",
    "# 5) bs.select(path) : elements 찾음 :list type으로 리턴\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘과 바람과 별과 시\n",
      "- 서시\n",
      "죽는 날까지 하늘을 우러러\n",
      "한 점 부끄럼이 없기를,\n",
      "잎새에 이는 바람에도\n",
      "나는 괴로워했다.\n",
      "별을 노래하는 마음으로\n",
      "모든 죽어가는 것을 사랑해야지\n",
      "그리고 나한테 주어진 길을\n",
      "걸어가야겠다.\n",
      "\n",
      "오늘 밤에도 별이 바람에 스치운다.\n",
      "\n",
      "- 자화상\n",
      "산모퉁이를 돌아 논가 외딴 우물을 홀로 찾아가선 가만히 들여다봅니다.\n",
      "우물 속에는 달이 밝고 구름이 흐르고 하늘이 펼치고 파아란 바람이 불고 가을이 있습니다.\n",
      "\n",
      "그리고 한 사나이가 있습니다.\n",
      "어쩐지 그 사나이가 미워져 돌아갑니다.\n",
      "\n",
      "돌아가다 생각하니 그 사나이가 가엾어집니다.\n",
      "도로 가 들여다보니 사나이는 그대로 있습니다.\n",
      "\n",
      "다시 그 사나이가 미워져 돌아갑니다.\n",
      "돌아가다 생각하니 그 사나이가 그리워집니다.\n",
      "\n",
      "우물 속에는 달이 밝고 구름이 흐르고 하늘이 펼치고 파아란 바람이 불고 가을이 있고 추억처럼 사나이가 있습니다.\n",
      "\n",
      "- 소년\n",
      "None\n",
      "- 눈 오는 지도\n",
      "순이(順伊)가 떠난다는 아침에 말 못할 마음으로 함박눈이 내려, 슬픈 것처럼 창 밖에 아득히 깔린 지도 위에 덮인다. \n",
      "\n",
      "방 안을 돌아다 보아야 아무도 없다. 벽과 천정이 하얗다. 방 안에까지 눈이 내리는 것일까, 정말 너는 잃어버린 역사처럼 홀홀이 가는 것이냐. 떠나기 전에 일러둘 말이 있던 것을 편지를 써서도 네가 가는 곳을 몰라 어느 거리, 어느 마을, 어느 지붕 밑, 너는 내 마음 속에만 남아 있는 것이냐. 네 쪼그만 발자욱을 눈이 자꾸 내려 덮어 따라갈 수도 없다. 눈이 녹으면 남은 발자욱 자리마다 꽃이 피리니 꽃 사이로 발자욱을 찾아 나서면 일년 열두달 하냥 내 마음에는 눈이 내리리라.\n",
      "\n",
      "- 돌아와 보는 밤\n",
      "세상으로부터 돌아오듯이 이제 내 좁은방에 돌아와 불을 끄옵니다.\n",
      "불을 켜 두는 것은 너무나 괴로롭은 일이옵니다.\n",
      "그것은 낮의 연장(延長)이옵기에-\n",
      " \n",
      "이제 창문窓을 열어 공기(空氣)를 바꾸어 들여야 할텐데\n",
      "밖을 가만히 내다 보아야 방(房)안과 같이 어두어 꼭 세상 같은데\n",
      "비를 맞고 오는 길이 그대로 비속에 젖어 있사옵니다.\n",
      " \n",
      "하로의 울분을 씻을바 없어 가만히 눈을 감으면\n",
      "마음속으로 흐르는 소리,\n",
      " \n",
      "이제,\n",
      " \n",
      "사상(思想)이 능금처럼 저절로 익어 가옵니다.\n",
      "\n",
      "- 병원\n",
      "살구나무 그늘로 얼굴을 가리고, 병원 뒤뜰에 누워, 젊은 여자가 흰 옷 아래로 하얀 다리를 드러내 놓고 일광욕을 한다. 한나절이 기울도록 가슴을 앓는 다는 이 여자를 찾아오는 이, 나비 한 마리도 없다. 슬프지도 않은 살구나무 가지에는 바람조차 없다.\n",
      "\n",
      "나도 모를 아픔을 오래 참다 처음으로 이 곳에 찾아 왔다. 그러나 나의 늙은 의사는 젊은이의 병을 모른다. 나한테는 병이 없다고 한다. 이 지나친 시련, 이 지나친 피로, 나는 성내서는 안 된다.\n",
      "\n",
      "여자는 자리에서 일어나 옷깃을 여미고 화단에서 금잔화 한 포기를 따 가슴에 꽂고 병실 안으로 사라진다. 나는 그 여자의 건강이 ---- 아니 내 건강도 속히 회복되기를 바라며 그가 누웠던 자리에 누워 본다.\n",
      "\n",
      "- 새로운 길\n",
      "내를 건너서 숲으로 \n",
      "고개를 넘어서 마을로 \n",
      "\n",
      "어제도 가고 오늘도 갈 \n",
      "나의 길 새로운 길 \n",
      "\n",
      "민들레가 피고 까치가 날고 \n",
      "아가씨가 지나고 바람이 일고 \n",
      "\n",
      "나의 길은 언제나 새로운 길 \n",
      "오늘도...... 내일도 ...... \n",
      "\n",
      "내를 건너서 숲으로 \n",
      "고개를 넘어서 마을로\n",
      "\n",
      "- 간판 없는 거리\n",
      "정거장 플랫포옴에\n",
      "내렸을 때, 아무도 없어\n",
      " \n",
      "다들 손님들뿐.\n",
      "손님 같은 사람들뿐.\n",
      " \n",
      "집집마다 간판이 없어\n",
      "집 찾을 근심이 없어.\n",
      " \n",
      "빨갛게,\n",
      "파랗게,\n",
      "불붙는 문자도 없이\n",
      " \n",
      "모퉁이마다\n",
      "자애로운 헌 와사등에\n",
      "불을 켜놓고,\n",
      " \n",
      "손목을 잡으면\n",
      "다들, 어진 사람들.\n",
      "다들, 어진 사람들.\n",
      " \n",
      "봄, 여름, 가을, 겨울\n",
      "순서로 돌아들고.\n",
      "\n",
      "- 태초의 아침\n",
      "봄날 아침도 아니고\n",
      "여름, 가을,겨울,\n",
      "그런 날 아침도 아닌 아침에\n",
      "빠알간 꽃이 피어났네,\n",
      "햇빛이 프른데,\n",
      "그 전날 밤에\n",
      "그 전날 밤에\n",
      "모든것이 마련되었네,\n",
      "사랑은 뱀과 함께\n",
      "독(毒)은 어린꽃과 함께.\n",
      "\n",
      "- 또 태초의 아침\n",
      "하얗게 눈이 덮이었고\n",
      "전신주(電信柱)가 잉잉 울어\n",
      "하나님 말씀이 들려온다.\n",
      "무슨 계시(啓示)일까.\n",
      "빨리\n",
      "봄이 오면\n",
      "죄(罪)를 짓고\n",
      "눈이\n",
      "밝아\n",
      "이브가 해산(解産)하는 수고를 다하면\n",
      "무화과(無花果) 잎사귀로 부끄런 데를 가리고\n",
      "나는 이마에 땀을 흘려야겠다.\n",
      "\n",
      "- 새벽이 올 때까지\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request as req\n",
    "url=\"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res=req.urlopen(url).read()\n",
    "soup=bs(res,\"html.parser\")\n",
    "li_list=soup.select(\"div.mw-parser-output > ul > li\")\n",
    "base=\"https://ko.wikisource.org/\"\n",
    "for title in li_list:\n",
    "    print(title.a.string)\n",
    "    li=title.select('li')\n",
    "    if len(li)>0:\n",
    "        for i in li:\n",
    "            print(\"-\", i.a.string)\n",
    "            url=i.a.attrs['href']\n",
    "            res=req.urlopen(base+url).read()\n",
    "            soup=bs(res,\"html.parser\")\n",
    "            #print(res)\n",
    "            content=soup.select_one(\"div.mw-parser-output > div > p\")\n",
    "            if content!=None:\n",
    "                content=content.getText()\n",
    "            else:\n",
    "                content='None'\n",
    "            print(content)\n",
    "    else:\n",
    "        url=title.a.attrs['href']\n",
    "        res=req.urlopen(base+url).read()\n",
    "        soup=bs(res,\"html.parser\")\n",
    "        content=soup.select_one(\"div.mw-parser-output > div > p\")\n",
    "        print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr><th>\n",
      "Item Title\n",
      "</th><th>\n",
      "Description\n",
      "</th><th>\n",
      "Cost\n",
      "</th><th>\n",
      "Image\n",
      "</th></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html=req.urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "soup=bs(html,'html.parser')\n",
    "for child in soup.find('table',{'id':'giftList'}).children:\n",
    "    print(child)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sibling in soup.find('table',{'id':'giftList'}).tr.next_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/gifts/logo.jpg\n",
      "../img/gifts/img1.jpg\n",
      "../img/gifts/img2.jpg\n",
      "../img/gifts/img3.jpg\n",
      "../img/gifts/img4.jpg\n",
      "../img/gifts/img6.jpg\n",
      "\n",
      "$15.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_urls=soup.find_all('img')\n",
    "for img in img_urls:\n",
    "    print(img.attrs['src'])\n",
    "    \n",
    "print(soup.find('img',{'src':'../img/gifts/img1.jpg'})\n",
    "     .parent.previous_sibling.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager,process_pdf\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from io import StringIO\n",
    "from io import open\n",
    "from urllib.request import urlopen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
